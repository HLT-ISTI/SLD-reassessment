{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive, IntProgress, TwoByTwoLayout\n",
    "from latex_results import load_measure_for_classifiers_pickles, normalized_absolute_error, LR_KEY, MNB_KEY, SVM_KEY, RF_KEY\n",
    "from plotly_colors import colors\n",
    "import random\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from load_data import get_measures_mean_across_experiments, jupyter_measures\n",
    "from drift_analysis import extract_binary_data\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "def extract_measures(meas_mean, isomerous):\n",
    "    nae = np.array(\n",
    "        [normalized_absolute_error(em_pr, test_pr) for em_pr, test_pr in zip(meas_mean.em_priors[1], meas_mean.test_priors[1])]\n",
    "    )\n",
    "    if isomerous:\n",
    "        cal = np.array(meas_mean.isomerous_em_cal_loss[1])\n",
    "        ref = np.array(meas_mean.isomerous_em_ref_loss[1])\n",
    "    else:\n",
    "        cal = np.array(meas_mean.isometric_em_cal_loss[1])\n",
    "        ref = np.array(meas_mean.isometric_em_ref_loss[1])\n",
    "\n",
    "    brier = cal + ref\n",
    "    return nae, brier, cal, ref\n",
    "\n",
    "MINORITY_CLASS, RANDOM_CLASS = range(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id='plot_mean'></a>\n",
    "## Visualize NAE, BS, CE and RE plots\n",
    "In this section you can select the experiments on SLD based on the number of target classes (2, 5, 10, 20, 37) and\n",
    "visualize the plots for each of the above measures. The data is averaged on the 500 experiments run as indicated\n",
    "in *Paper ref*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34e40cf20f94924852ef569a034c9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='Metrics', options=(('Abs. err.', 'abs_errors'), ('Brier', 'bâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def plot_experiments_for_class(class_):\n",
    "    progress = IntProgress(min=0, max=100, description=\"Loading data...\", bar_style='info', style={'description_width': 'initial'})\n",
    "    display(progress)\n",
    "    # Sort by classifier name\n",
    "    measures = sorted(load_measure_for_classifiers_pickles(\"rcv1\", class_), key=lambda m: m[0])\n",
    "    global fig\n",
    "    if fig is not None and type(fig) is go.FigureWidget:\n",
    "        fig.close()\n",
    "\n",
    "    if class_ == \"2\":\n",
    "        measures = list(map(lambda m: (m[0], list(m[1])), extract_binary_data(measures)))\n",
    "\n",
    "    clf_data = {j: {} for j in jupyter_measures.keys()}\n",
    "    max_len = 0\n",
    "    progress.description = 'Extracting data...'\n",
    "    progress.value = 0\n",
    "    for clf_name, data in measures:\n",
    "        measure_mean = get_measures_mean_across_experiments(data)\n",
    "        nae, brier, cal, ref = extract_measures(measure_mean, True)\n",
    "        if (l := nae.shape[0]) > max_len:\n",
    "            max_len = l\n",
    "        clf_data['nae'][clf_name] = nae\n",
    "        clf_data['bs'][clf_name] = brier\n",
    "        clf_data['ce'][clf_name] = cal\n",
    "        clf_data['re'][clf_name] = ref\n",
    "        progress.value += 100 / len(measures)\n",
    "\n",
    "    fig = make_subplots(rows=2, cols=2, subplot_titles=[v for v in sorted(jupyter_measures.values())])\n",
    "    i = 0\n",
    "    progress.description = 'Plotting data...'\n",
    "    progress.value = 0\n",
    "    for metric, clf_measures in sorted(clf_data.items(), key=lambda kv: kv[0]):\n",
    "        picked_colors = set()\n",
    "        for clf_name, value in clf_measures.items():\n",
    "            row = math.ceil((i+1) / 2)\n",
    "            col = 1 if (i+1) % 2 == 0 else 2\n",
    "            pad_width = (0, max_len - len(value))\n",
    "            if len(value.shape) > 1:\n",
    "                padded = np.pad(value, (pad_width, (0, 0)), mode='edge')\n",
    "            else:\n",
    "                padded = np.pad(value, pad_width, mode='edge')\n",
    "\n",
    "            random.seed(a=hash(clf_name))\n",
    "            color = random.choice(colors)\n",
    "\n",
    "            # Keep selecting a color until we find one we haven't already used\n",
    "            while color in picked_colors:\n",
    "                color = random.choice(colors)\n",
    "            picked_colors.add(color)\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=np.array(range(max_len)),\n",
    "                    y=padded,\n",
    "                    mode='lines',\n",
    "                    name=clf_name,\n",
    "                    visible='legendonly',\n",
    "                    legendgroup=clf_name,\n",
    "                    showlegend=row == 1 and col == 1,\n",
    "                    line={'color': color}\n",
    "                ), row=row, col=col\n",
    "            )\n",
    "        i += 1\n",
    "        progress.value += 100 / len(clf_data)\n",
    "\n",
    "    fig.update_layout(autosize=False, width=900, height=400 * (math.log2(len(jupyter_measures))))\n",
    "    fig.update_xaxes(automargin=True, title_text=\"SLD iterations\")\n",
    "    fig.update_yaxes(automargin=True)\n",
    "    progress.close()\n",
    "    fig = go.FigureWidget(fig)\n",
    "    display(fig)\n",
    "\n",
    "                \n",
    "fig = None\n",
    "\n",
    "w = widgets.Dropdown(options=['2', '5', '10', '20', '37'], value='5', description='Target classes', disabled=False,\n",
    "                   style={'description_width': 'initial'})\n",
    "w_disp = interactive(plot_experiments_for_class, class_=w)\n",
    "display(w_disp)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare metrics on two random samples\n",
    "In this section you can compare several metrics on two randomly chosen samples. You can select one out of the seven\n",
    "available classifiers we used to run our experiments."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_two_random_sample(_):\n",
    "    progress = IntProgress(min=0, max=100, description=\"Loading data...\", bar_style='info', style={'description_width': 'initial'})\n",
    "    display(progress)\n",
    "    measures = list(filter(lambda k: k[0] == select_classifier.value, load_measure_for_classifiers_pickles(\"rcv1\", select_class.value)))\n",
    "    global fig, fig2\n",
    "    if fig is not None and type(fig) is go.FigureWidget:\n",
    "        fig.close()\n",
    "    if fig2 is not None and type(fig2) is go.FigureWidget:\n",
    "        fig2.close()\n",
    "\n",
    "    progress.value = 50\n",
    "    if select_class.value == \"2\":\n",
    "        measures = list(map(lambda m: (m[0], list(m[1])), extract_binary_data(measures)))\n",
    "\n",
    "    random_sample = random.choice(measures[0][1])\n",
    "    max_len = len(random_sample.em_priors[1])\n",
    "    fig = go.FigureWidget()\n",
    "\n",
    "    if select_target.value == MINORITY_CLASS:\n",
    "        target_class = np.argmin(random_sample.train_priors[1][0]) if hasattr(random_sample.train_priors[1][0], '__len__') else 0\n",
    "    else:\n",
    "        target_class = random.choice(range(int(select_class.value))) if select_class.value != \"2\" else 0\n",
    "\n",
    "    test_priors = random_sample.test_priors[1][0]\n",
    "    test_priors = np.array([test_priors[0][target_class]]) if len(test_priors.shape) > 1 else np.array([test_priors])\n",
    "    em_priors = np.array(random_sample.em_priors[1])\n",
    "    train_priors = random_sample.train_priors[1][0]\n",
    "    train_priors = np.array([train_priors[0][target_class]]) if len(train_priors.shape) > 1 else np.array([train_priors])\n",
    "    # At iteration 0 we show the true train priors (which are our initial priors in the SLD\n",
    "    # algorithm, see em.py and em_test.py in this repository)\n",
    "    em_priors[0] = train_priors\n",
    "    nae, brier, cal, ref = extract_measures(random_sample, True)\n",
    "    progress.description = 'Plotting data...'\n",
    "\n",
    "    for name, value in [('Prior in unlabelled set', test_priors),('Prior in labelled set', train_priors),\n",
    "                        ('Prior generated by SLD', em_priors)]:\n",
    "        pad_width = (0, max_len - len(value))\n",
    "        if len(value.shape) > 1:\n",
    "            padded = np.pad(value, (pad_width, (0, 0)), mode='edge')\n",
    "        else:\n",
    "            padded = np.pad(value, pad_width, mode='edge')\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=np.array(range(max_len)),\n",
    "                y=padded[:, target_class] if len(value.shape) > 1 else padded,\n",
    "                mode='lines',\n",
    "                name=name,\n",
    "                visible='legendonly',\n",
    "                legendgroup=name,\n",
    "                # line={'color': color},\n",
    "            )\n",
    "        )\n",
    "        progress.value += 7\n",
    "\n",
    "    fig2 = go.FigureWidget()\n",
    "    for name, value in [('NAE', nae), ('BS', brier), ('CE', cal), ('RE', ref)]:\n",
    "        pad_width = (0, max_len - len(value))\n",
    "        if len(value.shape) > 1:\n",
    "            padded = np.pad(value, (pad_width, (0, 0)), mode='edge')\n",
    "        else:\n",
    "            padded = np.pad(value, pad_width, mode='edge')\n",
    "\n",
    "        fig2.add_trace(\n",
    "            go.Scatter(\n",
    "                x=np.array(range(max_len)),\n",
    "                y=padded[:, target_class] if len(value.shape) > 1 else padded,\n",
    "                mode='lines',\n",
    "                name=name,\n",
    "                visible='legendonly',\n",
    "                legendgroup=name,\n",
    "                # line={'color': color},\n",
    "            )\n",
    "        )\n",
    "        progress.value += 7\n",
    "\n",
    "    fig.update_layout(xaxis_title='SLD Iterations', title='Priors', legend=dict(y=1.2, x=.2, orientation='h'))\n",
    "    fig2.update_layout(xaxis_title='SLD Iterations', title='Metrics', legend=dict(y=1.2, x=.3, orientation='h'))\n",
    "    progress.close()\n",
    "    display(fig)\n",
    "    display(fig2)\n",
    "\n",
    "\n",
    "classifier_keys = [LR_KEY, RF_KEY, MNB_KEY]\n",
    "classifier_keys = sorted([\"Calibrated-\" + c for c in classifier_keys] + classifier_keys + [SVM_KEY])\n",
    "classifier_options = [(c.replace('-', ' '), c) for c in classifier_keys]\n",
    "fig = None\n",
    "fig2 = None\n",
    "\n",
    "select_classifier = widgets.Dropdown(options=classifier_options, description=\"Classifier\")\n",
    "select_class = widgets.Dropdown(options=['2', '5', '10', '20', '37'], value='5', description='Target classes',\n",
    "                                style={'description_width': 'initial'})\n",
    "select_target = widgets.Dropdown(options=[(\"Minority class\", MINORITY_CLASS), (\"Random class\", RANDOM_CLASS)],\n",
    "                                 description='Plot class')\n",
    "confirm_button = widgets.Button(description='Confirm', button_style='info')\n",
    "confirm_button.on_click(plot_two_random_sample)\n",
    "\n",
    "TwoByTwoLayout(\n",
    "    top_left=select_classifier,\n",
    "    top_right=select_target,\n",
    "    bottom_left=select_class,\n",
    "    bottom_right=confirm_button,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}